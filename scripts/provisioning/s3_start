#!/usr/bin/env python3
#
# Copyright (c) 2021 Seagate Technology LLC and/or its Affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# For any questions about this software or licensing,
# please email opensource@seagate.com or cortx-questions@seagate.com.
#

import sys
import argparse
import traceback
import errno
import logging
import os
import shutil
import socket
import time
from logging import handlers
from s3confstore.cortx_s3_confstore import S3CortxConfStore
from cortx.utils.cortx.const import Const
from cortx.utils.log import Log

def main():
  """

  Main method takes care of calling
  a startup script of service given
  as a argument.

  """
  parser = argparse.ArgumentParser("S3server single entry command")
  parser.add_argument("--service", required=True)
  parser.add_argument("--index", required=False)
  parser.add_argument("-c", required=True)

  args = parser.parse_args()


  # global variables
  global s3_confkeys_store
  global base_config_path
  global logger

  try:
    if not args.c:
      raise Exception("provide confstore_url")
    confstore_url = args.c

    # Load confstore file
    s3_confkeys_store = S3CortxConfStore\
        (f'yaml:///opt/seagate/cortx/s3/mini-prov/s3_prov_config.yaml', \
          's3_index')
    prov_confkeys_store = S3CortxConfStore(f'{confstore_url}', \
          'prov_index')
    machine_id = s3_confkeys_store.get_machine_id()

    # Get Config entries
    config_key = s3_confkeys_store.get_config\
                     ("CONFIG>CONFSTORE_BASE_CONFIG_PATH")

    base_config_path = prov_confkeys_store.get_config(config_key)
    logdir_key = s3_confkeys_store.get_config\
                     ("CONFIG>CONFSTORE_BASE_LOG_PATH")
    base_logdir_path = prov_confkeys_store.get_config(logdir_key)

    #Logging path details
    s3_single_entry_logger_name = s3_confkeys_store.get_config\
        ('S3_DEPLOYMENT_LOGGER_NAME')
    s3_single_entry_logger_backup_count = s3_confkeys_store.get_config\
        ('S3_DEPLOYMENT_LOGGER_BACKUP_COUNT')
    s3_single_entry_logger_max_size_mb = s3_confkeys_store.get_config\
        ('S3_DEPLOYMENT_LOGGER_MAX_SIZE_MB')
    s3_single_entry_log_directory = os.path.join\
        (base_logdir_path, "s3", machine_id, s3_single_entry_logger_name)

    create_logger_directory(s3_single_entry_log_directory)
    Log.init(s3_single_entry_logger_name, s3_single_entry_log_directory,
             level='INFO', backup_count=s3_single_entry_logger_backup_count,
             file_size_in_mb=s3_single_entry_logger_max_size_mb,
             syslog_server=None, syslog_port=None, console_output=True)

    # Service mapping
    service = args.service

    # Constant service names from utils.
    service_haproxy = Const.SERVICE_S3_HAPROXY.value
    service_s3server = Const.SERVICE_S3_SERVER.value
    service_authserver = Const.SERVICE_S3_AUTHSERVER.value
    service_bgscheduler = Const.SERVICE_S3_BGSCHEDULER.value
    service_bgworker = Const.SERVICE_S3_BGWORKER.value

    # follwing mapping needs to be removed once the services names are changed in provisioner and solution framework
    ######### start
    services_map = {
                "s3server": service_s3server,
                "s3authserver": service_authserver,
                "s3bgproducer": service_bgscheduler,
                "s3bgconsumer": service_bgworker,
                "haproxy": service_haproxy}
    Log.info(f"Input Service: {service}")
    if service in services_map:
        service = services_map[service]
    Log.info(f"Mapped Service: {service}")
    ######### end

    if service == service_s3server:
      if not args.index:
        raise Exception("provide instance id")

      # get the s3 config file path from S3 Provisioner config file
      s3configfile = s3_confkeys_store.get_config("S3_CONFIG_FILE").replace("/opt/seagate/cortx", base_config_path)
      Log.info(f"s3configfile : {s3configfile}")
      # create symbolic link for this config file to be used by log rotation
      create_symbolic_link(s3configfile, s3_confkeys_store.get_config("S3_CONF_SYMLINK"))

      # configure s3server, s3m0trace, s3addb logrotate
      configure_log_rotate("S3_LOGROTATE_S3LOG", "/etc/cron.hourly/")
      configure_log_rotate("S3_LOGROTATE_M0TRACE", "/etc/cron.hourly/")
      configure_log_rotate("S3_LOGROTATE_ADDB", "/etc/cron.hourly/")
      configure_log_rotate("S3_LOGROTATE_AUDITLOG", "/etc/cron.daily/")

      # start crond
      os.system("/usr/sbin/crond start")

      #Sys config path
      sysconfig_path = os.path.join(base_config_path, "s3", "sysconfig",machine_id)

      fid_file = "s3server-" + args.index
      fid_path = os.path.join(sysconfig_path, fid_file)
      Fid = get_fid(fid_path)

      Log.info(f"sh /opt/seagate/cortx/s3/s3startsystem.sh -F {Fid} -P {fid_path} -C {s3configfile} -d")
      Log.info(f"Starting S3 Server with FID {Fid}...")
      i = 0
      while i < 10:
        # Start S3 Server
        os.system(f"sh /opt/seagate/cortx/s3/s3startsystem.sh -F {Fid} -P {fid_path} -C {s3configfile} -d")
        i += 1
        time.sleep(60)

      # Read the log directory path from s3config file
      s3_log_dir = read_config_value("S3_CONFIG_FILE", "yaml", "S3_SERVER_CONFIG>S3_LOG_DIR")
      Log.info(f"s3_log_dir : {s3_log_dir}")
      # Append FID directory and SERVER.INFO
      s3_log_file_path = os.path.join(s3_log_dir, fid_file, "SERVER.INFO")
      Log.info(f"s3_log_file_path : {s3_log_file_path}")

      # Print last few line of S3 server log file
      os.system(f"tail -f {s3_log_file_path}")
    elif service == service_authserver:
      # Start S3 Auth Server
      Log.info(f"sh /opt/seagate/cortx/auth/startauth.sh {base_config_path}")
      Log.info(f"Starting S3 Auth Server...")
      os.system(f"sh /opt/seagate/cortx/auth/startauth.sh {base_config_path}")

      # Read the log directory path from s3 authserver config file
      s3_auth_server_log_dir = read_config_value("S3_AUTHSERVER_CONFIG_FILE", "properties", "logFilePath")
      Log.info(f"s3_auth_server_log_dir : {s3_auth_server_log_dir}")
      # Append app.log to directory path
      s3_auth_server_log_file_path = os.path.join(s3_auth_server_log_dir, "app.log")
      Log.info(f"s3_auth_server_log_file_path : {s3_auth_server_log_file_path}")

      # Print last few line of S3 authserver log  file
      os.system(f"tail -f {s3_auth_server_log_file_path}")
    elif service == service_bgscheduler:
      # Uncomment below two lines if you want return bgdelete schedule timings.
      # os.system("sed -i -e \"s,scheduler_schedule_interval:.*,scheduler_schedule_interval:\ 120,\" /etc/cortx/s3/s3backgrounddelete/config.yaml")
      # os.system("sed -i -e \"s,leak_processing_delay_in_mins:.*,leak_processing_delay_in_mins:\ 2,\" /etc/cortx/s3/s3backgrounddelete/config.yaml")
      # Start S3 Background Producer
      Log.info(f"sh /opt/seagate/cortx/s3/s3backgrounddelete/starts3backgroundproducer.sh {base_config_path} yaml://")
      Log.info(f"Starting S3 Background delete Producer...")
      os.system(f"sh /opt/seagate/cortx/s3/s3backgrounddelete/starts3backgroundproducer.sh {base_config_path} yaml://")

      # Read the log directory path from s3 bgdelete config file
      s3_bgdelete_producer_log_name = read_config_value("S3_BGDELETE_CONFIG_FILE", "yaml", "logconfig>scheduler_logger_name")
      s3_bgdelete_producer_log_dir = read_config_value("S3_BGDELETE_CONFIG_FILE", "yaml", "logconfig>scheduler_logger_directory")
      s3_bgdelete_producer_log_file_path = os.path.join(s3_bgdelete_producer_log_dir, f"{s3_bgdelete_producer_log_name}.log")
      Log.info(f"s3_bgdelete_producer_log_file_path : {s3_bgdelete_producer_log_file_path}")

      # Print last few line of S3 bgdelete producer log  file
      os.system(f"tail -f {s3_bgdelete_producer_log_file_path}")

    elif service == service_bgworker:
      # Start the Background Consumer
      Log.info(f"sh /opt/seagate/cortx/s3/s3backgrounddelete/starts3backgroundconsumer.sh {base_config_path} yaml://")
      Log.info(f"Starting S3 Background delete Consumer...")
      os.system(f"sh /opt/seagate/cortx/s3/s3backgrounddelete/starts3backgroundconsumer.sh {base_config_path} yaml://")

      # Read the log directory path from s3 bgdelete config file
      s3_bgdelete_consumer_log_name = read_config_value("S3_BGDELETE_CONFIG_FILE", "yaml", "logconfig>processor_logger_name")
      s3_bgdelete_consumer_log_dir = read_config_value("S3_BGDELETE_CONFIG_FILE", "yaml", "logconfig>processor_logger_directory")
      s3_bgdelete_consumer_log_file_path = os.path.join(s3_bgdelete_consumer_log_dir, f"{s3_bgdelete_consumer_log_name}.log")
      Log.info(f"s3_bgdelete_consumer_log_file_path : {s3_bgdelete_consumer_log_file_path}")

      # Print last few line of S3 bgdelete consumer log  file
      os.system(f"tail -f {s3_bgdelete_consumer_log_file_path}")

    elif service == service_haproxy:
      haproxy_log_path = os.path.join(base_logdir_path, 's3', machine_id, 'haproxy/haproxy.log')
      Log.info(f"haproxy_log_path: {haproxy_log_path}")
      # create haproxy log directory path if does not exist
      os.makedirs(os.path.dirname(haproxy_log_path), exist_ok=True)
      # create empty haproxy log file
      with open(haproxy_log_path, 'w') as fp:
          pass
      # create symbolic link for this config file to be used by log rotation
      create_symbolic_link(haproxy_log_path,s3_confkeys_store.get_config("S3_HAPROXY_LOG_SYMLINK"))

      # configure haproxy logrotate using logrotate.d script
      update_haproxy_log_rotate_file("/etc/logrotate.d/haproxy", "/var/log/haproxy.log", f"{haproxy_log_path}")

      # start crond
      os.system("/usr/sbin/crond start")

      # Start haproxy
      Log.info(f"sh /opt/seagate/cortx/s3/bin/starthaproxy.sh {base_config_path} {haproxy_log_path}")
      Log.info(f"Starting HAProxy...")
      os.system(f"sh /opt/seagate/cortx/s3/bin/starthaproxy.sh {base_config_path} {haproxy_log_path}")

      # Print last few line of S3 HAProxy log  file
      os.system(f"tail -f {haproxy_log_path}")
    else:
      Log.error(f"Service {service} is not supported")


  except Exception as e:
    Log.error(f"{str(e)}")
    Log.error(f"{traceback.format_exc()}")
    return errno.EINVAL

  return 0

def read_config_value(config_file_path,
                      config_file_type,
                      key_to_read):
    # get the  config file path from S3 Provisioner config file
    configfile = s3_confkeys_store.get_config(config_file_path).replace("/opt/seagate/cortx", base_config_path)
    if os.path.isfile(f'{configfile}') == False:
      raise Exception(f'{configfile} file is not present')

    # load config file (example: s3configfileconfstore = confstore object to /etc/cortx/s3/conf/s3config.yaml)
    s3configfileconfstore = S3CortxConfStore(f'{config_file_type}://{configfile}', 'read_config_file_log_dir' + key_to_read)

    # read the given key from the config file
    config_value = s3configfileconfstore.get_config(key_to_read)

    return config_value

def create_logger_directory(s3_single_entry_log_directory):
    """Create log directory if not exsists."""
    _logger_directory = os.path.join(s3_single_entry_log_directory)
    if not os.path.isdir(_logger_directory):
        try:
            os.makedirs(_logger_directory, exist_ok=True)
        except OSError as e:
            if e.errno == errno.EEXIST:
                pass
            else:
                raise Exception("Startup Logger Could not be created")

def get_fid(fid_path):
    """ Get FID from FID file"""
    Fid = None
    with open(fid_path) as file1:
      Lines = file1.readlines()
      for line in Lines:
        if(line.startswith('MOTR_PROCESS_FID')):
          Fid = line.split("=")[1]
          break
    if not Fid:
      raise Exception("FID is not present in Fid path")
    Fid = Fid.strip("\n")
    Fid = Fid.strip("''")

    return Fid

def configure_log_rotate(key_to_read: str, cron_dir: str):
    s3_logrotate_config_file = s3_confkeys_store.get_config(key_to_read)
    Log.info(f"s3_logrotate_config_file : {s3_logrotate_config_file}")
    os.makedirs(os.path.dirname(cron_dir), exist_ok=True)
    shutil.copy(s3_logrotate_config_file, cron_dir)
    Log.info("logrotate config file copied successfully to cron directory")

def create_symbolic_link(src_path: str, dst_path: str):
  """create symbolic link."""
  Log.info(f"symbolic link source path: {src_path}")
  Log.info(f"symbolic link destination path: {dst_path}")
  if os.path.exists(dst_path):
    Log.info(f"symbolic link is already present")
    os.unlink(dst_path)
    Log.info("symbolic link is unlinked")
  os.symlink(src_path, dst_path)
  Log.info(f"symbolic link created successfully")

def update_haproxy_log_rotate_file(filename: str,
                      content_to_search: str,
                      content_to_replace: str):
  """find and replace the haproxy log path and delete unwanted lines from logrotate file."""
  Log.info(f"log file path to search: {content_to_search}")
  Log.info(f"correct log file path prefix to replace: {content_to_replace}")
  # removing unwanted entries from logrotate file
  with open(filename) as f:
    newText=f.read().replace(content_to_search, content_to_replace)
  Log.debug(f"Updating haproxy log rotate file : {filename}")
  with open(filename, "w") as f:
    lines = newText.split("\n")
    for line in lines:
        entry=line.strip()
        if (entry.startswith("postrotate"))  \
          or  (entry.startswith("/bin/kill -HUP")) \
          or (entry.startswith("endscript")) \
          or (entry.startswith("rotate")) \
          or (entry.startswith("sharedscripts")) \
          or (entry.endswith("/haproxy-status.log")):
          # ignoring unwanted entries
          Log.debug(f"ignoring the entry : {entry}")
          pass
        elif (entry.startswith("}")):
          f.write("    rotate 5" +'\n')
          f.write("    size 5M" +'\n')
          f.write("    copytruncate" +'\n')
          f.write("    dateext" +'\n')
          f.write("    dateformat -%Y-%m-%d-%s" +'\n')
          f.write(line)
        else:
          f.write(line+'\n')
    Log.debug(f"Updated haproxy log rotate file successfully..")

  Log.info(f"haproxy log rotate file updation completed successfully :  {filename}.")

if __name__ == '__main__':
  sys.exit(main())
